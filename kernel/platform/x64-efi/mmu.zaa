//
// x86 mmu
//

import std.range;
import std.atomic;
import std.optional;
import platform.x64-efi.bootinfo;
import platform.x64-efi.cpu as cpu;

using platform::physaddr_t;
using platform::virtaddr_t;
using platform::physrange_t;
using platform::virtrange_t;

pub enum mflags
{
  zero,
  copy,
  keep,
}

pub enum mtype
{
  uncached,
  write_back,
  write_through,
  write_combine,
}

pub enum protection
{
  none,
  readonly,
  readwrite,
  executable,
}

pub struct page_table
{
  uintptr pml4;
  i32 refcnt;

  pub fn bool(this &) -> bool
  {
    return this.pml4 != 0;
  }

  pub fn ==(page_table lhs, page_table rhs) -> bool
  {
    return lhs.pml4 == rhs.pml4;
  }

  pub fn cnt(this mut &) -> i32
  {
    return std::atomic_load(&this.refcnt);
  }

  pub fn ref(this mut &) -> void
  {
    std::atomic_add(&this.refcnt, 1);
  }

  pub fn unref(this mut &) -> i32
  {
    return std::atomic_sub(&this.refcnt, 1);
  }

  page_table(uintptr cr3)
    : pml4(cr3)
  {
  }

  pub page_table() = default;
  pub page_table(page_table&) = default;
  pub fn =(page_table mut &, page_table&) -> page_table mut & = default;
  pub ~page_table() = default;
}

pub fn fmt(std::OutputStream mut &os, std::fmt_context mut &ctx, page_table &pagetable) throws(std::error) -> void
{
  ctx.written += std::format_to(&mut os, "page_table {{ cr3: {:#08x} }}", pagetable.pml4);
}

pub struct page_table_query
{
  uintptr entry;

  pub fn present(this &) -> bool { return this.entry & pdbits::present != 0; }
  pub fn writeable(this &) -> bool { return this.entry & pdbits::writeable != 0; }
  pub fn address(this &) -> physaddr_t { return physaddr_t(this.entry & 0x7ffffffffffff000); }

  page_table_query(uintptr entry)
    : entry(entry)
  {
  }

  pub page_table_query(page_table_query&) = default;
  pub fn =(page_table_query mut &, page_table_query &) ->page_table_query mut & = default;
  pub ~page_table_query() = default;
}

enum pdbits : u64
{
  present = 0x1,
  writeable = 0x2,
  user = 0x4,
  write_through	= 0x8,
  caching_disabled = 0x10,
  accessed = 0x20,
  dirty = 0x40,
  large = 0x80,
  pat = 0x80,
  global = 0x100,
  no_execute = 1 << 63,

  const fn &(uintptr lhs, pdbits rhs) -> uintptr { return lhs & cast(rhs); }
  const fn |(uintptr lhs, pdbits rhs) -> uintptr { return lhs | cast(rhs); }
}

fn pds(virtaddr_t addr) -> usize[3]
{
  return [ (addr >> 39) & 0x1ff, (addr >> 30) & 0x1ff, (addr >> 21) & 0x1ff ];
}

fn pte(virtaddr_t addr) -> usize
{
  return (addr >> 12) & 0x1ff;
}

pub fn is_user_address(virtaddr_t addr) -> bool
{
  return addr <= USER_LIMIT;
}

pub fn is_kernel_address(virtaddr_t addr) -> bool
{
  return addr >= KERNEL_SPACE;
}

pub fn pagetable() -> page_table
{
  return page_table(cpu::rdcr3());
}

pub fn activate(page_table mut &this) -> void
{
  if (cpu::rdcr3() != this.pml4)
    cpu::wrcr3(this.pml4);
}

pub fn new(page_table mut &this, fn (&allocate)() -> physaddr_t) -> void
{
  this.pml4 = allocate();

  var irqs = cpu::disable_interrupts();
  std::memset(cast<u8 mut *>(PHYSICAL_BASE + this.pml4), 0, 2048);
  std::memcpy(cast<u8 mut *>(PHYSICAL_BASE + this.pml4 + 2048), cast<u8 mut *>(PHYSICAL_BASE + cpu::rdcr3() + 2048), 2048);
  cpu::restore_interrupts(irqs);
}

pub fn query(page_table mut &this, virtaddr_t addr) -> page_table_query
{
  var pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + this.pml4);

  for (var i : pds(addr))
  {
    if (pt[i] & pdbits::present == 0)
      return page_table_query(0);

    pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (pt[i] & ~0xfff));
  }

  return page_table_query(pt[pte(addr)]);
}

pub fn map(page_table mut &this, virtaddr_t baseaddr, physrange_t pages, protection prot, mflags mflags, fn (&allocate)() -> physaddr_t) -> void
{
  var addr = baseaddr;
  var page = pages.0;

  while (page != pages.1)
  {
    var pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + this.pml4);

    for (var i : pds(addr))
    {
      var entry = std::atomic_load(&pt[i], std::memory_order::relaxed);

      while (entry & pdbits::present == 0)
      {
        var irqs = cpu::disable_interrupts();

        if (std::atomic_cmpxchg_strong(&pt[i], 0, 0xffe))
        {
          var addr = allocate();
          std::memset(cast<u8 mut *>(PHYSICAL_BASE + addr), 0, PAGE_SIZE);

          std::atomic_store(&pt[i], addr | pdbits::present | pdbits::writeable | pdbits::user);
        }

        cpu::restore_interrupts(irqs);

        entry = std::atomic_load(&pt[i], std::memory_order::relaxed);
      }

      pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (entry & ~0xfff));
    }

    for (var i = pte(addr); page != pages.1 && i < 512; ++i)
    {
      var flags = uintptr(0);

      if (prot == protection::readwrite)
        flags |= pdbits::writeable;

      if (prot != protection::executable)
        flags |= pdbits::no_execute;

      if (baseaddr < USER_LIMIT)
        flags |= pdbits::user;
      else
        flags |= pdbits::global;

      switch (mflags)
      {
        case zero:
          std::memset(cast<void mut *>(PHYSICAL_BASE + page), 0, PAGE_SIZE);

        case copy:
          std::memcpy(cast<void mut *>(PHYSICAL_BASE + page), cast<void mut *>(PHYSICAL_BASE + (pt[i] & 0x7ffffffffffff000)), PAGE_SIZE);
      }

      pt[i] = page | pdbits::present | flags;

      if (cpu::rdcr3() == this.pml4)
        cpu::invlpg(addr);

      addr += PAGE_SIZE;
      page += PAGE_SIZE;
    }
  }
}

pub fn set_memory_type(page_table mut &this, virtrange_t range, mtype mtype) -> void
{
  var addr = range.0;

  while (addr < range.1)
  {
    var pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + this.pml4);

    for (var i : pds(addr))
    {
      std::assert(pt[i] & pdbits::present != 0);

      pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (pt[i] & ~0xfff));
    }

    for (var i = pte(addr); addr < range.1 && i < 512; ++i)
    {
      std::assert(pt[i] != 0);

      switch (mtype)
      {
        case uncached:
          pt[i] = (pt[i] & ~0x98) | pdbits::caching_disabled | pdbits::write_through;

        case write_back:
          pt[i] = (pt[i] & ~0x98);

        case write_through:
          pt[i] = (pt[i] & ~0x98) | pdbits::write_through;

        case write_combine:
          pt[i] = (pt[i] & ~0x98) | pdbits::pat;
      }

      addr += PAGE_SIZE;
    }
  }
}

pub fn unmap(page_table mut &this, virtrange_t range) -> void
{
  var addr = range.0;

  while (addr < range.1)
  {
    var pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + this.pml4);

    for (var i : pds(addr))
    {
      std::assert(pt[i] & pdbits::present != 0);

      pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (pt[i] & ~0xfff));
    }

    for (var i = pte(addr); addr < range.1 && i < 512; ++i)
    {
      std::assert(pt[i] != 0);

      pt[i] = 0;

      if (cpu::rdcr3() == this.pml4)
        cpu::invlpg(addr);

      addr += PAGE_SIZE;
    }
  }

  //if (USER_LIMIT < range.begin)
  //  cpu::flush_global_tlb();
}

pub fn unmap(page_table mut &this, virtrange_t range, void mut *data, fn (&callback)(void mut *, virtaddr_t, physaddr_t) -> void) -> void
{
  var addr = range.0;

  while (addr < range.1)
  {
    var pds = pds(addr);

    var pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + this.pml4);

    if (pt[pds[0]] & pdbits::present != 0)
    {
      pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (pt[pds[0]] & ~0xfff));

      if (pt[pds[1]] & pdbits::present != 0)
      {
        pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (pt[pds[1]] & ~0xfff));

        if (pt[pds[2]] & pdbits::present != 0)
        {
          pt = cast<uintptr[512] mut *>(PHYSICAL_BASE + (pt[pds[2]] & ~0xfff));

          for (var i = pte(addr); addr < range.1 && i < 512; ++i)
          {
            if (pt[i] & pdbits::present != 0)
            {
              var page = pt[i] & 0x7ffffffffffff000;

              pt[i] = 0;

              if (cpu::rdcr3() == this.pml4)
                cpu::invlpg(addr);

              callback(data, addr, page);
            }

            addr += PAGE_SIZE;
          }
        }
        else
          addr += PAGE_SIZE << 9;
      }
      else
        addr += PAGE_SIZE << 18;
    }
    else
      addr += PAGE_SIZE << 27;
  }

  //if (USER_LIMIT < range.begin)
  //  cpu::flush_global_tlb();
}

pub fn dispose(page_table mut &this, void mut *data, fn (&callback)(void mut *, physaddr_t) -> void) -> void
{
  var pml4 = cast<physaddr_t[512] mut *>(PHYSICAL_BASE + this.pml4);

  for (var k = 0; k < 256; ++k)
  {
    if (pml4[k] & pdbits::present != 0)
    {
      var pdp = cast<physaddr_t[512] mut *>(PHYSICAL_BASE + (pml4[k] & ~0xfff));

      for (var j = 0; j < 512; ++j)
      {
        if (pdp[j] & pdbits::present != 0)
        {
          var pd = cast<physaddr_t[512] mut *>(PHYSICAL_BASE + (pdp[j] & ~0xfff));

          for (var i = 0; i < 512; ++i)
          {
            if (pd[i] & pdbits::present != 0)
            {
              var pt = cast<physaddr_t[512] mut *>(PHYSICAL_BASE + (pd[i] & ~0xfff));

              for (var i = 0; i < 512; ++i)
                std::assert(pt[i] == 0);

              callback(data, pd[i] & ~0xfff);
            }
          }

          callback(data, pdp[j] & ~0xfff);
        }
      }

      callback(data, pml4[k] & ~0xfff);
    }
  }

  callback(data, this.pml4);

  this.pml4 = 0;
}
